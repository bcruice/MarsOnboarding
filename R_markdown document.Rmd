---
title: "Hello World - pwdgsi, performance metrics, and me"
author: "Brian cruice"
date: "`r lubridate::now()`"
output: html_document
params:
  database: "PostgreSQL35W"
  write: TRUE
---
```{r setup, include=FALSE}
#Database Stuff
library(odbc)
library(tidyverse)
library(lubridate)
library(pwdgsi)
library(sf)
library(padr)
#Other stuff
library(knitr)
library(ggtext)
library(DT)
options(stringsAsFactors=FALSE)
```

## R Markdown {.tabset}



### Working with iris Data
Working in R markdown is a familiar experience, even if my skills are a _bit_ rusty. Today we'll be reviewing some data in the *iris* data set including in R, primarily through the use of the *dplyr* and *ggplot* packages, which are a part of the larger *tidyverse* set of packages. Below are a few simple plots of the data without any manipulation. Below we have the simplest form of boxplot output for ggplot.

```{r, echo = FALSE}
datatable(iris)

iris.box <- ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot()
iris.width.plot <- ggplot(iris, aes(x= Sepal.Width, y = Petal.Width, col = Species)) + geom_point()

iris.box


```

Isn't it awful? Why are  the whiskers tied to individual data points? Why can't we see those data points? Doesn't the rest of the box represent descriptive statistics of the dataset? Can't we just see all of the data as well as a representation of the spread in one graph? Also, we need to make the labels clearer and make the whole thing pop. Let's clean it up. We'll need to know some ggplot, some dplyr, and some base stat functions to get there.

```{r echo = TRUE} 
petal.stats <- quantile(iris$Petal.Length)
#set lower whisker to lower hinge - 1.5*IQR
petal.whisk.min <- petal.stats[2] - 1.5*(petal.stats[4]-petal.stats[2])
#set upper whisker to upper hinge + 1.5*IQR
petal.whisk.max <- petal.stats[4] + 1.5*(petal.stats[4]-petal.stats[2])

petal.stats <- iris %>% group_by(Species) %>%
               summarize("low.whisk" = quantile(Petal.Length)[2] - 1.5*(quantile(Petal.Length)[4]-quantile(Petal.Length)[2]),
                         "up.whisk" = quantile(Petal.Length)[4] + 1.5*(quantile(Petal.Length)[4]-quantile(Petal.Length)[2]))

iris.box.better <- ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot(outlier.shape =NA,
                                                                                   ymin = petal.stats$low.whisk,
                                                                                   ymax = petal.stats$up.whisk) +
                   geom_jitter(width= 0.15, alpha = 0.5, aes(col = Species)) +
                   xlab("Species") + ylab("Petal Length (cm)") + ggtitle("Spread of Petal Length by Species")
iris.box.better
```

Isn't that just better? Now lets make a table summarizing some of what we see here. Once we're done reviewing, we can move on to the MARS data.

```{r echo = FALSE}
petal.stats.2 <- iris %>% group_by(Species) %>%
                          summarize("Mean Length (cm)" = mean(Petal.Length),
                                    "Median Length (cm)" = median(Petal.Length),
                                    "Lower Quartile (cm)" = quantile(Petal.Length)[2],
                                    "Upper Quartile (cm)" = quantile(Petal.Length)[4],
                                    "Minimum Length (cm)" = min(Petal.Length),
                                    "Maximum Length (cm)" = max(Petal.Length)
                                    )

datatable(petal.stats.2)
```



### Working with MARS Data
Working with pwdgsi, we are able to grab data from several tables within the **mars_testing** database and save them as lists or database objects in R.

#### Running pwdgsi Functions
```{r Section 0 - Preamble and database connections, include=FALSE}
###Section 0.1: Check parameter validity
	if(!(params$database %in% c("PostgreSQL35W","mars", "mars_testing"))){
		stop(paste("Invalid database parameter:", params$database))
	}
###Section 0.2: Connect to the database
	#Indicate the database name: mars_testing or mars. 
	#Only write to mars if you really know what you're doing.
	mars<- dbConnect(odbc::odbc(), params$database)
	
```
Below is the beginning of the level data for 250-1-1 during the period of 01/01/2019 to 09/01/2021. This is one of three dataframes created by queries to the **mars_testing** database performed by the function **marsFetchMonitoringData**.
```{r, echo = FALSE}

#Set paramters

#set parameters
smpId <- "250-1-1"
owId <- "OW1"
start_date <- as.POSIXct("2019-01-01")
end_date <- as.POSIXct("2021-09-01")

#use existing function to create list of data surrounding SMP 250-1-1
smp_250_1_1 <- marsFetchMonitoringData(mars,
                        target_id = smpId,
                        ow_suffix = owId,
                        start_date = start_date,
                        end_date = end_date,
                        source = "radar",
                        sump_correct = TRUE)



rain_event_data <- smp_250_1_1[["Rain Event Data"]]
rain_data <- smp_250_1_1[["Rainfall Data"]] %>% mutate(across(dtime_est), - hours(5))
rain_data <- smp_250_1_1[["Rainfall Data"]]
level_data <- smp_250_1_1[["Level Data"]]
level_data <- smp_250_1_1[["Level Data"]]

head(smp_250_1_1$`Level Data`)
```

#### Replicating pwdgsi Functions
The functions in **pwdgsi** are there to streamline common queries to the MARS database. However, to better understand the code behind the functions and their intended purposes, I'm showing how I would recreate the list object outputted by **marsFetchMonitoringData** using the functions in the R packages **odbc** and  **DBI**.
```{r, echo = TRUE}
#Save a vector of tables to find the appropriate ones to query.
mars_tables <- dbListTables(mars)

#Initiate a null list to populate with dataframes from queries.
smp250_1_1 <- list()


#Query targetId
targetId <- dbGetQuery(mars,
                       paste0("SELECT ow_uid FROM fieldwork.ow WHERE smp_id = '",
                              smpId,
                               "' AND ow_suffix = '",
                              owId, "'")
                      )


#Query level data
level_data <- dbGetQuery(mars,
                        paste0(
                          "SELECT o.dtime_est, o.level_ft, o.ow_uid
                            FROM data.ow_leveldata_raw o
                            WHERE o.ow_uid = ", targetId)
)

smp250_1_1$`Level Data` <- level_data %>%
                            dplyr::filter(dtime_est >= start_date) %>%
                           dplyr::filter(dtime_est <= end_date)
head(smp250_1_1$`Level Data`)

```
This is close to the level data grabbed by **marsFetchMonitoringData**, but it still needs to be joined to rain gauge data and rainfall events and processed to no longer be "raw" data. I also suspect that filtering for time after the query whether than building it into the query is a more process intensive way of reaching this result.

#### SMP 250-1-1â˜º
Rather than continuing to replicate an existing function, let's inspect the data for 250-1-1. Let's create some summary statistics for these data.

##### Summary Statistics

```{r echo = FALSE}
event_means <- smp_250_1_1$`Rain Event Data` %>%
                 summarise(Event_duration_avg_hr = mean(eventduration_hr),
                           Event_depth_avg_in = mean(eventdepth_in),
                           Event_peak_int_avg_inhr = mean(eventpeakintensity_inhr),
                           count = n())

```

The total number of rain events between `r start_date` and `r end_date` is `r event_means$count`.

The mean duration of these `r event_means$count` events was `r round(event_means$Event_duration_avg_hr,2)` hours with a mean peak intensity of `r round(event_means$Event_peak_int_avg_inhr, 2)` in/hr and a mean depth of `r round(event_means$Event_depth_avg_in, 2)` inches. 


#### View Key Metrics
```{r echo = FALSE, include = FALSE}

#Pull snapshot of data from time in question
snapshot <- marsFetchSMPSnapshot(con = mars,
                                         smp_id = smpId,
                                         ow_suffix = owId,
                                         request_date = end_date)


#join monitoring data in one table
  obs_data <- dplyr::full_join(smp_250_1_1[["Level Data"]], smp_250_1_1[["Rainfall Data"]], 
                                 by = c("dtime_est", "radar_uid", "radar_event_uid")) %>% 
    dplyr::arrange(dtime_est) %>%
    dplyr::mutate(across(c("level_ft", "ow_uid"), ~ zoo::na.locf(., na.rm = FALSE))) %>%
    dplyr::mutate(across(c("level_ft", "ow_uid"), ~ zoo::na.locf(., fromLast = TRUE))) %>% 
    dplyr::mutate(orifice_outflow_ft3 = marsUnderdrainOutflow_cf(dtime_est = dtime_est,
                                                                waterlevel_ft = level_ft,
                                                                orifice_height_ft = snapshot$assumption_orificeheight_ft,
                                                                orifice_diam_in = snapshot$orifice_diam_in))

 #set initial water levels so the simulation starts at the same spot as observed
    initial_water_levels <- obs_data %>% 
      dplyr::group_by(radar_event_uid) %>%
      dplyr::summarize(
        ft = dplyr::first(level_ft)
      )
    
    initial_water_levels <- initial_water_levels[complete.cases(initial_water_levels), ]
    

    #observed ---- 
    
    #create a summary table of observed data
    observed_summary <- obs_data %>%
      dplyr::arrange(dtime_est) %>% 
      dplyr::filter(is.na(radar_event_uid) == FALSE) %>% #remove rows that had water level data but no event ID
      #dplyr::filter(radar_event_uid == 159691) %>% 
      dplyr::group_by(radar_event_uid) %>%
      dplyr::summarize(
        
        #Ow uid
        ow_uid = ow_uid[1],
        
        # first_point = dplyr::first(level_ft), 
        
        #Observed storage utilization
        percentstorageused_peak = marsPeakStorage_percent(waterlevel_ft = level_ft, storage_depth_ft = snapshot$storage_depth_ft) %>% round(4),
        
        #Observed relative storage utilization
        percentstorageused_relative = marsPeakStorage_percent(waterlevel_ft = level_ft - dplyr::first(level_ft), storage_depth_ft = snapshot$storage_depth_ft) %>% round(4),
        
        baseline = marsWaterLevelBaseline_ft(dtime_est = dtime_est, 
                                             level_ft = level_ft),
        
        infiltration_inhr = marsInfiltrationRate_inhr(event = radar_event_uid,
                                                      dtime_est = dtime_est,
                                                      rainfall_in = rainfall_in,
                                                      snapshot$dcia_ft2,
                                                      snapshot$assumption_orificeheight_ft,
                                                      snapshot$orifice_diam_in,
                                                      storage_depth_ft = snapshot$storage_depth_ft,
                                                      #storage_depth_ft = 1,
                                                      storage_vol_ft3 = snapshot$storage_volume_ft3,
                                                      waterlevel_ft = level_ft,
                                                      depth_in = 6),
        
        #Draindown time
        draindown_hr = marsDraindown_hr(dtime_est = dtime_est,
                                        rainfall_in = rainfall_in,
                                        waterlevel_ft = level_ft),
        
        draindownAssessment = marsDraindownAssessment(level_ft = level_ft, 
                                                      eventdepth_in =
                                                      rain_event_data$eventdepth_in[which(rain_event_data$radar_event_uid ==
                                                                                            radar_event_uid[1])], 
                                                      designdepth_in = snapshot$storage_volume_ft3/snapshot$dcia_ft2*12, 
                                                      storage_depth_ft = snapshot$storage_depth_ft, 
                                                      draindown_hr = draindown_hr, 
                                                      subsurface = TRUE, 
                                                      event_id_check = radar_event_uid[1]), 
        
        overtop = marsOvertoppingCheck_bool(level_ft, snapshot$storage_depth_ft),
        
        peakReleaseRate_cfs = marsPeakReleaseRate_cfs(dtime_est, orifice_outflow_ft3 = orifice_outflow_ft3),
        
        orifice_volume_cf = round(sum(orifice_outflow_ft3),0),
        
        snapshot_uid = snapshot$snapshot_uid,
        
        observed_simulated_lookup_uid = 1
      )

      obs_sim_summary <- observed_summary

      #count events with -900 errors
      error.count <- sum(obs_sim_summary$infiltration_inhr == -900)
      
      #check mean depth of these events
      error.events <- obs_sim_summary %>% dplyr::filter(infiltration_inhr == -900) %>%
                      left_join(rain_event_data, by = "radar_event_uid")
      error.mean.size <- error.events %>% summarize(MeanEventDepth_in = mean(eventdepth_in))
                      
      
```

We've now run some code (courtesy of Nick Manna) that let's us look at the key metrics for each storm event within the period. The table below includes all events within the timeframe. As you can see, `r round((error.count/nrow(obs_sim_summary))*100,1)`% of all events received the -900 error for infiltration rate, with the mean depth of these events being `r error.mean.size` inches. This means the event does not include observation data that approximately equals specified water depth. These events will not be useful for testing system functionality. Instead we should try filtering the table to display the largest storms first. 

```{r echo = FALSE}
datatable(obs_sim_summary)
```


#### Plotting MARS Data
Below are the plots for draw down for `r smpId` during the two largest events, by total precipitation depth, measured between the dates `r format(start_date,"%D")` and `r format(end_date, "%D")`.

```{r echo = FALSE, include=FALSE}

rain_event_data %<>% dplyr::arrange(desc(eventdepth_in))

#only select the five largest storms
 for(j in 1:10){
 # for(j in 1:length(rain_event_data$radar_event_uid)){
     #j <-1
     #filter for each event
       selected_event <- obs_data %>%
         dplyr::filter(radar_event_uid == rain_event_data$radar_event_uid[j])
       rain_plot_data <- smp_250_1_1[["Rainfall Data"]] %>%
         dplyr::filter(radar_event_uid == rain_event_data$radar_event_uid[j])

       #only plot rain events greater than 0.5". this can be modified as desired
       if(rain_event_data$eventdepth_in[j] > 0.5){
       #skip plots with errors -900
       #just plot observed
        if(obs_sim_summary$infiltration_inhr[j] != -900){
           #   # plot observed data
           plot <- marsCombinedPlot(event = rain_event_data$radar_event_uid[j],
                                    structure_name = paste(smpId, owId),
                                    obs_datetime = selected_event$dtime_est,
                                    obs_level_ft = selected_event$level_ft,
                                    storage_depth_ft = snapshot$storage_depth_ft,
                                    orifice_show = TRUE,
                                    orifice_height_ft = snapshot$assumption_orificeheight_ft,
                                    rainfall_datetime = rain_plot_data$dtime_est,
                                    rainfall_in = rain_plot_data$rainfall_in,
                                    #raingage = rain_plot_data$gage_uid,
                                    obs_infiltration_rate_inhr = obs_sim_summary$infiltration_inhr[j],
                                    obs_draindown_hr = paste(obs_sim_summary$draindown_hr[j], "| Score:", ... = obs_sim_summary$draindownAssessment[j]),
                                    obs_percent_storage_relative = round(obs_sim_summary$percentstorageused_relative[j],2))

         # }
         #save plot
         #put errors in a different folder
         #if(obs_sim_summary$infiltration_inhr[j] > -900){
           # ggplot2::ggsave(paste0(folder, "/", paste(target_id, ow_suffix, rain_event_data$radar_event_uid[j], sep = "_"),".png"), plot = plot, width = 10, height = 8)
         #}else if(obs_sim_summary$infiltration_inhr[j] != -900){
          ggplot2::ggsave(paste0(getwd(), "/", paste(smpId, owId, rain_event_data$radar_event_uid[j], sep = "_"),".png"), plot = plot, width = 10, height = 8)
        # }
       }
       }
 }

```

```{r echo =  FALSE}
include_graphics(paste0(getwd(), "/", paste(smpId, owId, rain_event_data$radar_event_uid[1], sep = "_"),".png"))
include_graphics(paste0(getwd(), "/", paste(smpId, owId, rain_event_data$radar_event_uid[2], sep = "_"),".png"))

```

